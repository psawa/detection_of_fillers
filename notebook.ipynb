{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wget --accept wav --mirror --page-requisites --adjust-extension --convert-links --backup-converted --no-parent https://media.talkbank.org/ca/CallHome/eng/0wav/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence level alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pydub/utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from os import walk, listdir\n",
    "from pydub import AudioSegment\n",
    "import re\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "speechs = {}\n",
    "\n",
    "class Speech():\n",
    "    def __init__(self, identifier):\n",
    "        self._id = identifier\n",
    "        self.audio_path = './corpus/original_audio/'+identifier+'.wav'\n",
    "        self.transc_path = './corpus/original_text/'+identifier+'.cha'\n",
    "        self.sentences = [] #dictionnaries like {start (ms), end, text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instances\n",
    "for filename in listdir('./corpus/original_audio/'):\n",
    "        if filename.endswith('.wav'):\n",
    "            _id = filename.split('.')[0]\n",
    "            speechs[_id] = Speech(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_lines(content):\n",
    "        try:\n",
    "            content = re.split('@Media.*audio\\n',content)[1]\n",
    "        except:\n",
    "            return \n",
    "        content = re.split('\\n@End\\n',content)[0]\n",
    "        lines = re.split('(\\x15.*\\x15)', content)\n",
    "        lines2 = []\n",
    "        i = 0\n",
    "        pattern = re.compile('\\x15.*\\x15')\n",
    "        while i<len(lines):\n",
    "            elem = lines[i]\n",
    "            while not pattern.match(lines[i]) and i!=len(lines)-1: #tant ne contient pas (ou n'est pas) un timestamp:\n",
    "                i += 1\n",
    "                next_elem = lines[i]\n",
    "                next_elem = next_elem.replace('*B:', ' ')\n",
    "                next_elem = next_elem.replace('*A:', ' ')\n",
    "                elem = elem + ' ' + next_elem #on concatenate avec l'Ã©lement suivant\n",
    "            #quand on tombe sur un timestamp\n",
    "            elem = elem.replace('\\n\\t', ' ')\n",
    "            elem = elem.replace('\\n', '')\n",
    "            elem = elem.replace('\\t','')\n",
    "            elem = elem.replace('*A:',' ')\n",
    "            elem = elem.replace('*B:',' ')\n",
    "            elem= elem[1:]\n",
    "            \n",
    "            lines2.append(elem)\n",
    "            i += 1 \n",
    "    \n",
    "        lines2 = lines2[:-1]\n",
    "        return lines2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences retrieved\n"
     ]
    }
   ],
   "source": [
    "# Spotting the sentences\n",
    "for speech in speechs.values():\n",
    "        with open(speech.transc_path) as transc_file:\n",
    "            content = transc_file.read()\n",
    "            \n",
    "        #splitting after each timestamp\n",
    "        lines= get_clean_lines(content)\n",
    "        if lines == None:\n",
    "            continue\n",
    "        \n",
    "        for i in range(len(lines)):\n",
    "            lines[i] = lines[i].rstrip()\n",
    "        for line in lines:\n",
    "            try:\n",
    "                timestamp = re.search(\"\\x15(.*)\\x15\", line).group(1)\n",
    "            except:\n",
    "                breakpoint()\n",
    "            start = int(timestamp.split(\"_\")[0])\n",
    "            end = int(timestamp.split(\"_\")[1])\n",
    "            #breakpoint()\n",
    "            text = re.search(\"(.*)\\x15{}\".format(timestamp),line).group(1)\n",
    "            #writing in the speech object\n",
    "            speech.sentences.append({'start':start,'end':end, 'text':text})\n",
    "print(\"Sentences retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutting ./corpus/original_audio/0638.wav\n"
     ]
    }
   ],
   "source": [
    "# Creating files\n",
    "for speech in speechs.values():\n",
    "        print('Cutting {}'.format(speech.audio_path))\n",
    "        data, samplerate = sf.read(speech.audio_path)\n",
    "        for sent in speech.sentences:\n",
    "            title = \"{}_{}_{}\".format(speech._id, sent['start'], sent['end'])\n",
    "            cut = data[sent['start']*int((samplerate/1000)):sent['end']*int((samplerate/1000))]\n",
    "            sf.write('./corpus/alignment/sentence_level_audio/{}.wav'.format(title),cut , samplerate)\n",
    "            with open('./corpus/alignment/sentence_level_text/{}.txt'.format(title),'w') as outfile:\n",
    "                print(sent['text'], file = outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering non-filler utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('(mhm|uhhuh|mm|um|eh|em|ah|huh|ha|er|oof|hee|ach|eee|ew)')\n",
    "\n",
    "for file in glob.iglob('./corpus/alignment_sentence_level_text/'):\n",
    "    filename = file.split('.')[-1]\n",
    "    filename = filename.split('.')[0]\n",
    "    has_filler = False\n",
    "    with open(file,'r', encoding = 'utf-8') as infile:\n",
    "        content = infile.read()\n",
    "        matched = re.match(pattern, content)\n",
    "        has_filler = bool(matched)\n",
    "    if not has_filler:\n",
    "        system('rm {}'.format(file))\n",
    "        system('rm ./corpus/alignment_sentence_level_audio/{}.wav'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word level alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the audio sentences into mono\n",
    "path = './corpus/alignment/sentence_level_audio/'\n",
    "for filename in listdir(path):\n",
    "    system('sox {}{} {}{} remix 1,2'.format(path, filename, path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the setup for MFA\n",
    "# (converting .txt to .lab, and moving .lab and .wav sentence level into the same folder)\n",
    "\n",
    "for filename in listdir('./corpus/alignment/sentence_level_audio'):\n",
    "    _id = filename.split('.')[0]\n",
    "    system('mv ./corpus/alignment/sentence_level_audio/{}.wav ./corpus/alignment/mfa_setup/{}.wav '.format(_id,_id))\n",
    "    system('mv ./corpus/alignment/sentence_level_text/{}.txt ./corpus/alignment/mfa_setup/{}.lab'.format(_id,_id))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfa_path = ??? # Replace with the installation directory of Montreal Forced Aligner\n",
    "lm_path = '../corpus/alignment/librispeech-lexicon.txt' # Language model\n",
    "lab_wav_path = '../corpus/alignment/mfa_setup'\n",
    "output_path = '../corpus/alignment/textgrids'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfa command\n",
    "system('{}\\bin\\mfa_align.exe -v  {} {} english {}'.format(mfa_path, lm_path, lab_wav_path, output_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textgrids as tg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hesitations = [\n",
    "    'mhm',\n",
    "    'uhhuh',\n",
    "    'mm',\n",
    "    'um',\n",
    "    'eh',\n",
    "    'em',\n",
    "    'ah',\n",
    "    'huh',\n",
    "    'ha',\n",
    "    'er',\n",
    "    'oof',\n",
    "    'hee',\n",
    "    'ach',\n",
    "    'eee',\n",
    "    'ew'\n",
    "]\n",
    "\n",
    "silence = ['sp', 'sil','']\n",
    "\n",
    "def tag_word(word):\n",
    "    if word in hesitations: \n",
    "        return 'hesitation'\n",
    "    elif word in silence:\n",
    "        return 'silence'\n",
    "    else:\n",
    "        return 'speech'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can jump until the end if you have the pickles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame(columns=['file','word','tag','xmin','xmax'])\n",
    "files_df = pd.DataFrame(columns=['file', 'xmin','xmax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in listdir('./corpus/alignment/textgrids'):\n",
    "    if not filename.endswith('.TextGrid'):\n",
    "        continue\n",
    "    name = filename.split('.')[0]\n",
    "    the_tg = tg.TextGrid('./corpus/alignment/textgrids/'+filename)\n",
    "    \n",
    "    # Filling the dataframe of files\n",
    "    files_df.loc[len(files_df)] = {'file':name,\n",
    "                            'xmin':the_tg.xmin,\n",
    "                            'xmax':the_tg.xmax}\n",
    "    \n",
    "    # Filling the dataframe of words \n",
    "    for word in the_tg['words']:\n",
    "        words_df.loc[len(words_df)] = {'file':name,\n",
    "                             'word':word.text,\n",
    "                             'tag':tag_word(word.text),\n",
    "                             'xmin':word.xmin,\n",
    "                             'xmax':word.xmax\n",
    "                            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0638_440130_440740</td>\n",
       "      <td>um</td>\n",
       "      <td>hesitation</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0638_440130_440740</td>\n",
       "      <td></td>\n",
       "      <td>silence</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0638_210130_210500</td>\n",
       "      <td>uhhuh</td>\n",
       "      <td>hesitation</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0638_210130_210500</td>\n",
       "      <td></td>\n",
       "      <td>silence</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0638_694970_696670</td>\n",
       "      <td>mm</td>\n",
       "      <td>hesitation</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file   word         tag  xmin  xmax\n",
       "0  0638_440130_440740     um  hesitation  0.00  0.59\n",
       "1  0638_440130_440740            silence  0.59  0.61\n",
       "2  0638_210130_210500  uhhuh  hesitation  0.00  0.35\n",
       "3  0638_210130_210500            silence  0.35  0.37\n",
       "4  0638_694970_696670     mm  hesitation  0.00  0.51"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df['duration'] = words_df['xmax']-words_df['xmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12a975390>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOwElEQVR4nO3dcYzfd13H8eeLjgqRZRh7Gm27XYMd0gCO7KwaFUHBdFlsJU7TBhOWoI1KgxE1lGAq1sRMZiSG1EhFyGLEMibqwU6LDIgGHeltTKAtlUst9tI/OMYcKLiu8PaP+w1//vq7+33v9rve+tnzkVzy+36/n/v+3lu2Z7/93v1+v1QVkqSr3zPWewBJ0ngYdElqhEGXpEYYdElqhEGXpEZcs15PvGnTppqcnFyvp5ekq9IDDzzwxaqaGHZs3YI+OTnJ7Ozsej29JF2Vknx+qWPecpGkRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWpEp6An2ZXkTJK5JAeHHH9bkod6X/+W5D/HP6q0OkmuyJe03kYGPckG4AhwC7AD2JdkR/+aqvq1qrqpqm4C3g68fy2GlVajqlb0dcMbP7ji7/GDYvRU0OUKfScwV1Vnq+oicAzYs8z6fcBfjmM4SVJ3XYK+GTjftz3f23eZJDcA24CPLHF8f5LZJLMLCwsrnVWStIwuQR92c3Cpv1/uBe6pqq8PO1hVR6tqqqqmJiaGvlmYJGmVugR9Htjat70FuLDE2r14u0WS1kWXoJ8AtifZlmQji9GeHlyU5PnAtwH/Mt4RJUldjAx6VV0CDgDHgdPA3VV1MsnhJLv7lu4DjpU/7pekddHpAy6qagaYGdh3aGD7LeMbS5K0Ur5SVJIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqRGdgp5kV5IzSeaSHFxizc8lOZXkZJL3jHdMSdIo14xakGQDcAR4JTAPnEgyXVWn+tZsB94E/HBVPZLkO9ZqYEnScF2u0HcCc1V1tqouAseAPQNrfhE4UlWPAFTVF8Y7piRplC5B3wyc79ue7+3rdyNwY5KPJ7k/ya5hJ0qyP8lsktmFhYXVTSxJGqpL0DNkXw1sXwNsB14G7APemeS5l31T1dGqmqqqqYmJiZXOKklaRpegzwNb+7a3ABeGrPnbqnq8qv4dOMNi4CVJV0iXoJ8AtifZlmQjsBeYHljzN8DLAZJsYvEWzNlxDipJWt7IoFfVJeAAcBw4DdxdVSeTHE6yu7fsOPBwklPAR4HfrKqH12poSdLlRv7aIkBVzQAzA/sO9T0u4A29L0nSOvCVopLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUiE5BT7IryZkkc0kODjl+e5KFJA/1vn5h/KNKkpYz8kOik2wAjgCvBOaBE0mmq+rUwNL3VtWBNZhRktRBlyv0ncBcVZ2tqovAMWDP2o4lSVqpLkHfDJzv257v7Rv0M0k+leSeJFuHnSjJ/iSzSWYXFhZWMa4kaSldgp4h+2pg+wPAZFW9GPgwcNewE1XV0aqaqqqpiYmJlU0qSVpWl6DPA/1X3FuAC/0Lqurhqnqst/mnwM3jGU+S1FWXoJ8AtifZlmQjsBeY7l+Q5Lv6NncDp8c3oiSpi5G/5VJVl5IcAI4DG4B3VdXJJIeB2aqaBl6fZDdwCfgScPsazixJGmJk0AGqagaYGdh3qO/xm4A3jXc0SdJK+EpRSWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRnQKepJdSc4kmUtycJl1tyWpJFPjG1GS1MXIoCfZABwBbgF2APuS7Biy7lrg9cAnxj2kJGm0LlfoO4G5qjpbVReBY8CeIet+F3gr8D9jnE+S1FGXoG8Gzvdtz/f2fVOSlwBbq+qDy50oyf4ks0lmFxYWVjysJGlpXYKeIfvqmweTZwBvA3591Imq6mhVTVXV1MTERPcpJUkjdQn6PLC1b3sLcKFv+1rghcDHkpwDfhCY9gejknRldQn6CWB7km1JNgJ7geknDlbVo1W1qaomq2oSuB/YXVWzazKxJGmokUGvqkvAAeA4cBq4u6pOJjmcZPdaDyhJ6uaaLouqagaYGdh3aIm1L3vyY0mSVspXikpSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDWi04dEJ9kF/BGwAXhnVd0xcPyXgNcBXwf+C9hfVafGPKvE9/3Oh3j0a4+v+fNMHrx3zZ/jumc/k3/97Z9c8+fR08fIoCfZABwBXgnMAyeSTA8E+z1V9Se99buBPwR2rcG8epp79GuPc+6OW9d7jLG4En9o6Omlyy2XncBcVZ2tqovAMWBP/4Kq+nLf5rcCNb4RJUlddLnlshk437c9D/zA4KIkrwPeAGwEfnzYiZLsB/YDXH/99SudVZK0jC5X6Bmy77Ir8Ko6UlXPA94I/NawE1XV0aqaqqqpiYmJlU0qSVpWl6DPA1v7trcAF5ZZfwz46SczlCRp5boE/QSwPcm2JBuBvcB0/4Ik2/s2bwU+N74RJUldjLyHXlWXkhwAjrP4a4vvqqqTSQ4Ds1U1DRxI8grgceAR4DVrObQk6XKdfg+9qmaAmYF9h/oe/+qY55IkrZCvFJWkRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRnQKepJdSc4kmUtycMjxNyQ5leRTSe5LcsP4R5UkLWdk0JNsAI4AtwA7gH1Jdgws+yQwVVUvBu4B3jruQSVJy+tyhb4TmKuqs1V1ETgG7OlfUFUfraqv9jbvB7aMd0xJ0ihdgr4ZON+3Pd/bt5TXAn837ECS/Ulmk8wuLCx0n1KSNFKXoGfIvhq6MPl5YAq4c9jxqjpaVVNVNTUxMdF9SknSSNd0WDMPbO3b3gJcGFyU5BXAm4Efq6rHxjOeJKmrLlfoJ4DtSbYl2QjsBab7FyR5CfAOYHdVfWH8Y0qSRhkZ9Kq6BBwAjgOngbur6mSSw0l295bdCTwHeF+Sh5JML3E6SdIa6XLLhaqaAWYG9h3qe/yKMc8lSVqhTkGXniqufcFBXnTXZa9tuypd+wKAW9d7DDXEoOuq8pXTd3DujjYiOHnw3vUeQY3xvVwkqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIa0SnoSXYlOZNkLsllH+iY5KVJHkxyKclt4x9TkjTKyKAn2QAcAW4BdgD7kuwYWPYfwO3Ae8Y9oCSpmy4fEr0TmKuqswBJjgF7gFNPLKiqc71j31iDGSVJHXS55bIZON+3Pd/bt2JJ9ieZTTK7sLCwmlNIkpbQJegZsq9W82RVdbSqpqpqamJiYjWnkCQtoUvQ54GtfdtbgAtrM44kabW6BP0EsD3JtiQbgb3A9NqOJUlaqZFBr6pLwAHgOHAauLuqTiY5nGQ3QJLvTzIP/CzwjiQn13JoSdLluvyWC1U1A8wM7DvU9/gEi7diJEnrxFeKSlIjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNaLT2+dKTyWTB+9d7xHG4rpnP3O9R1BjDLquKufuuHXNn2Py4L1X5HmkcfOWiyQ1wit0NS/Jyr/n91f+PFW18m+Sxsigq3mGVk8XnW65JNmV5EySuSQHhxz/liTv7R3/RJLJcQ8qSVreyKAn2QAcAW4BdgD7kuwYWPZa4JGq+h7gbcAq/sIqSXoyulyh7wTmqupsVV0EjgF7BtbsAe7qPb4H+Ims5salJGnVugR9M3C+b3u+t2/omqq6BDwKfPs4BpQkddMl6MOutAd/ytRlDUn2J5lNMruwsNBlPklSR12CPg9s7dveAlxYak2Sa4DrgC8NnqiqjlbVVFVNTUxMrG5iSdJQXYJ+AtieZFuSjcBeYHpgzTTwmt7j24CPlL8rJklX1MjfQ6+qS0kOAMeBDcC7qupkksPAbFVNA38G/HmSORavzPeu5dCSpMtlvS6kkywAn1+XJ5eWtwn44noPIS3hhqoaes963YIuPVUlma2qqfWeQ1op35xLkhph0CWpEQZdutzR9R5AWg3voUtSI7xCl6RGGHRJaoRBV3OSvCXJb4zhPM9N8it929+d5J4ne15prRh0Pa313ntoKc8Fvhn0qrpQVbet/VTS6hh0NSHJm3ufqvVh4Pm9fR9LMtV7vCnJud7j25O8L8kHgA8leU6S+5I8mOTTSZ54v/87gOcleSjJnUkmk3ymd45nJXl3b/0nk7y879zvT/L3ST6X5K1X+F+Fnsb8TFFd9ZLczOL7B72Exf+mHwQeGPFtPwS8uKq+1LtKf1VVfTnJJuD+JNPAQeCFVXVT73km+77/dQBV9aIk38viHww39o7d1JvlMeBMkrdXVf9nCkhrwqCrBT8K/HVVfRWgF+NR/qGqnniL5wC/l+SlwDdY/MCW7xzx/T8CvB2gqj6b5PPAE0G/r6oe7c1yCriB//8hMdKaMOhqxbAXVFzi/24rPmvg2H/3PX41MAHcXFWP927NDK4ftNxHLD7W9/jr+P+ZrhDvoasF/wi8Ksmzk1wL/FRv/zng5t7j5X6YeR3whV7MX87iFTXAV4Brl3nOVwP0brVcD5xZ9T+BNAYGXVe9qnoQeC/wEPBXwD/1Dv0B8MtJ/pnFt8Rdyl8AU0lmWYz0Z3vnfRj4eJLPJLlz4Hv+GNiQ5NO95769qh5DWke+9F+SGuEVuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ14n8BpnfeDMaUEsMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words_df['duration'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to ms\n",
    "words_df['xmin'] = words_df['xmin'].apply(lambda x: int(x*1000))\n",
    "words_df['xmax'] = words_df['xmax'].apply(lambda x: int(x*1000))\n",
    "words_df['duration'] = words_df['duration'].apply(lambda x: int(x*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "hesitation    52\n",
       "silence       86\n",
       "speech        73\n",
       "Name: file, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.groupby('tag').count().file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0638_440130_440740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0638_210130_210500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0638_694970_696670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0638_388380_388790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0638_710110_710620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file  xmin  xmax\n",
       "0  0638_440130_440740   0.0  0.61\n",
       "1  0638_210130_210500   0.0  0.37\n",
       "2  0638_694970_696670   0.0  1.70\n",
       "3  0638_388380_388790   0.0  0.41\n",
       "4  0638_710110_710620   0.0  0.51"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df['duration'] = files_df['xmax']-files_df['xmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to ms\n",
    "files_df['xmin'] = files_df['xmin'].apply(lambda x: int(x*1000))\n",
    "files_df['xmax'] = files_df['xmax'].apply(lambda x: int(x*1000))\n",
    "files_df['duration'] = files_df['duration'].apply(lambda x: int(x*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.to_pickle('./pickles/words_df.pkl')\n",
    "files_df.to_pickle('./pickles/files_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.read_pickle('./pickles/words_df.pkl')\n",
    "files_df = pd.read_pickle('./pickles/files_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framing audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_decision_med(filename, xmin, xmax):\n",
    "    # Taking the median sample\n",
    "    med = int((xmin+xmax)/2)\n",
    "    query = words_df.query(\"file=='{}' and {} >= xmin and {} <= xmax \".format(filename, med, med))\n",
    "    tag = query.iloc[0]['tag']\n",
    "    return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2int = {\n",
    "    '<dummy>':0,\n",
    "    'speech':1,\n",
    "    'silence':2,\n",
    "    'hesitation':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 16000\n",
    "win_shift = 12.5\n",
    "win_len = 12.5\n",
    "numb_files = len(files_df)\n",
    "max_len = int(files_df['duration'].max() // win_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Skip the following if you have tags.pt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.zeros((numb_files,max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 52\n",
      "2 / 52\n",
      "3 / 52\n",
      "4 / 52\n",
      "5 / 52\n",
      "6 / 52\n",
      "7 / 52\n",
      "8 / 52\n",
      "9 / 52\n",
      "10 / 52\n",
      "11 / 52\n",
      "12 / 52\n",
      "13 / 52\n",
      "14 / 52\n",
      "15 / 52\n",
      "16 / 52\n",
      "17 / 52\n",
      "18 / 52\n",
      "19 / 52\n",
      "20 / 52\n",
      "21 / 52\n",
      "22 / 52\n",
      "23 / 52\n",
      "24 / 52\n",
      "25 / 52\n",
      "26 / 52\n",
      "27 / 52\n",
      "28 / 52\n",
      "29 / 52\n",
      "30 / 52\n",
      "31 / 52\n",
      "32 / 52\n",
      "33 / 52\n",
      "34 / 52\n",
      "35 / 52\n",
      "36 / 52\n",
      "37 / 52\n",
      "38 / 52\n",
      "39 / 52\n",
      "40 / 52\n",
      "41 / 52\n",
      "42 / 52\n",
      "43 / 52\n",
      "44 / 52\n",
      "45 / 52\n",
      "46 / 52\n",
      "47 / 52\n",
      "48 / 52\n",
      "49 / 52\n",
      "50 / 52\n",
      "51 / 52\n",
      "52 / 52\n"
     ]
    }
   ],
   "source": [
    "i,j = 0,0\n",
    "\n",
    "for audiofile in files_df['file']:\n",
    "    j = 0\n",
    "    filename = audiofile\n",
    "    file_df = files_df.query(\"file == '{}'\".format(filename))\n",
    "    duration = file_df.iloc[0]['duration']\n",
    "    head = 0\n",
    "    while head + win_shift <= duration:\n",
    "        try:\n",
    "            tag = tag2int[tag_decision_med(filename, head, head+win_len )]\n",
    "            Y[i][j] = tag\n",
    "        except:\n",
    "            continue\n",
    "        head += win_shift\n",
    "        j += 1\n",
    "    i += 1\n",
    "    print('{} / {}'.format(i,numb_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 323])\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3.,  ..., 0., 0., 0.],\n",
      "        [3., 3., 3.,  ..., 0., 0., 0.],\n",
      "        [3., 3., 3.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [3., 3., 3.,  ..., 0., 0., 0.],\n",
      "        [2., 2., 3.,  ..., 0., 0., 0.],\n",
      "        [3., 3., 3.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([13593,  1495,   305,  1403]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(Y, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tags,'./pickles/Y.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.load('./pickles/Y.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_tensors = []\n",
    "\n",
    "for audiofile in files_df['file']:\n",
    "    waveform, sample_rate = torchaudio.load('./corpus/alignment/mfa_setup/'+audiofile+'.wav')\n",
    "    mfcc = torchaudio.transforms.MFCC(n_mfcc=13)(waveform)\n",
    "    torch.set_printoptions(sci_mode=False)\n",
    "    mfcc_tensors.append(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_tensors = []\n",
    "\n",
    "for tensor in mfcc_tensors:\n",
    "    target = torch.zeros(1, 13, max_len+1)\n",
    "    source = tensor\n",
    "    target[:, :, :tensor.shape[2]] = source\n",
    "    padded_tensors.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.cat((padded_tensors), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 13, 324])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.narrow(X, 2, 0, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 13, 323])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 323])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 1, 323])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X,'./pickles/X.pt')\n",
    "torch.save(Y,'./pickles/Y.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.load('./pickles/X.pt')\n",
    "Y = torch.load('./pickles/Y.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.load('./pickles/X.pt')\n",
    "Y = torch.load('./pickles/Y.pt').squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 13, 323])\n",
      "torch.Size([52, 323])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "N_STEPS = X.shape[2]\n",
    "N_INPUTS = 13\n",
    "N_NEURONS = 150\n",
    "N_OUTPUTS = 4\n",
    "N_EPHOCS = 50\n",
    "LR = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X[:2500], X[2500:]\n",
    "Y_train, Y_valid = Y[:2500], Y[2500:]\n",
    "\n",
    "train_set = TensorDataset(X_train, Y_train)\n",
    "valid_set = TensorDataset(X_valid, Y_valid)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons)\n",
    "        \n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return (torch.zeros(1, self.batch_size, self.n_neurons))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        X = X.permute(1, 0, 2)\n",
    "\n",
    "        self.batch_size = X.size(1)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        lstm_out, self.hidden = self.basic_rnn(X, self.hidden)\n",
    "        out = self.FC(lstm_out)\n",
    "\n",
    "        return out.view(-1, self.n_outputs) # batch_size X n_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model instance\n",
    "model = RNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
    "criterion = nn.CrossEntropyLoss(size_average=True, ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "def get_accuracy(logit, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100 * corrects/batch_size\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 | Loss: 3.3945 | Train Accuracy: 19.16\n",
      "[[533 230 635]\n",
      " [164  21 108]\n",
      " [710 145 441]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.06      0.36      0.10      1495\n",
      "           2       0.01      0.07      0.02       305\n",
      "           3       0.09      0.31      0.14      1403\n",
      "\n",
      "   micro avg       0.06      0.31      0.11      3203\n",
      "   macro avg       0.05      0.25      0.09      3203\n",
      "weighted avg       0.07      0.31      0.11      3203\n",
      "\n",
      "Epoch:  2 | Loss: 5.3074 | Train Accuracy: 50.35\n",
      "[[375 496 301]\n",
      " [ 67  98  61]\n",
      " [345 320 343]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.25      0.13      1495\n",
      "           2       0.03      0.32      0.05       305\n",
      "           3       0.09      0.24      0.13      1403\n",
      "\n",
      "   micro avg       0.07      0.25      0.11      3203\n",
      "   macro avg       0.07      0.27      0.10      3203\n",
      "weighted avg       0.08      0.25      0.12      3203\n",
      "\n",
      "Epoch:  3 | Loss: 3.9629 | Train Accuracy: 57.08\n",
      "[[408  33 634]\n",
      " [ 86   9  95]\n",
      " [377  21 551]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      0.27      0.15      1495\n",
      "           2       0.02      0.03      0.03       305\n",
      "           3       0.09      0.39      0.14      1403\n",
      "\n",
      "   micro avg       0.09      0.30      0.14      3203\n",
      "   macro avg       0.07      0.23      0.10      3203\n",
      "weighted avg       0.09      0.30      0.13      3203\n",
      "\n",
      "Epoch:  4 | Loss: 3.2514 | Train Accuracy: 23.21\n",
      "[[440 598 286]\n",
      " [ 73 124  56]\n",
      " [328 576 328]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.12      0.29      0.17      1495\n",
      "           2       0.02      0.41      0.03       305\n",
      "           3       0.09      0.23      0.13      1403\n",
      "\n",
      "   micro avg       0.06      0.28      0.10      3203\n",
      "   macro avg       0.07      0.31      0.11      3203\n",
      "weighted avg       0.09      0.28      0.14      3203\n",
      "\n",
      "Epoch:  5 | Loss: 3.2663 | Train Accuracy: 24.41\n",
      "[[800  88 551]\n",
      " [161  28 100]\n",
      " [637 164 499]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.11      0.54      0.18      1495\n",
      "           2       0.01      0.09      0.02       305\n",
      "           3       0.09      0.36      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.41      0.14      3203\n",
      "   macro avg       0.07      0.33      0.11      3203\n",
      "weighted avg       0.09      0.41      0.15      3203\n",
      "\n",
      "Epoch:  6 | Loss: 2.7869 | Train Accuracy: 25.57\n",
      "[[507 338 439]\n",
      " [100  63 105]\n",
      " [531 216 486]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.07      0.34      0.12      1495\n",
      "           2       0.02      0.21      0.04       305\n",
      "           3       0.10      0.35      0.15      1403\n",
      "\n",
      "   micro avg       0.07      0.33      0.12      3203\n",
      "   macro avg       0.06      0.30      0.10      3203\n",
      "weighted avg       0.08      0.33      0.13      3203\n",
      "\n",
      "Epoch:  7 | Loss: 2.5131 | Train Accuracy: 14.40\n",
      "[[752 142 597]\n",
      " [127  37 141]\n",
      " [671 107 616]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.50      0.15      1495\n",
      "           2       0.03      0.12      0.04       305\n",
      "           3       0.09      0.44      0.15      1403\n",
      "\n",
      "   micro avg       0.08      0.44      0.14      3203\n",
      "   macro avg       0.07      0.35      0.11      3203\n",
      "weighted avg       0.08      0.44      0.14      3203\n",
      "\n",
      "Epoch:  8 | Loss: 2.5615 | Train Accuracy: 33.76\n",
      "[[796 238 179]\n",
      " [149  35  68]\n",
      " [728 171 284]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.53      0.16      1495\n",
      "           2       0.02      0.11      0.03       305\n",
      "           3       0.09      0.20      0.13      1403\n",
      "\n",
      "   micro avg       0.08      0.35      0.13      3203\n",
      "   macro avg       0.07      0.28      0.10      3203\n",
      "weighted avg       0.09      0.35      0.13      3203\n",
      "\n",
      "Epoch:  9 | Loss: 2.3747 | Train Accuracy: 22.54\n",
      "[[1021    1  441]\n",
      " [ 194    2   99]\n",
      " [ 962    4  366]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.68      0.16      1495\n",
      "           2       0.03      0.01      0.01       305\n",
      "           3       0.09      0.26      0.13      1403\n",
      "\n",
      "   micro avg       0.09      0.43      0.15      3203\n",
      "   macro avg       0.07      0.32      0.10      3203\n",
      "weighted avg       0.08      0.43      0.13      3203\n",
      "\n",
      "Epoch:  10 | Loss: 2.3364 | Train Accuracy: 21.49\n",
      "[[1095    7  372]\n",
      " [ 192    3   96]\n",
      " [ 965    1  384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.73      0.17      1495\n",
      "           2       0.08      0.01      0.02       305\n",
      "           3       0.09      0.27      0.14      1403\n",
      "\n",
      "   micro avg       0.09      0.46      0.15      3203\n",
      "   macro avg       0.09      0.34      0.11      3203\n",
      "weighted avg       0.09      0.46      0.14      3203\n",
      "\n",
      "Epoch:  11 | Loss: 2.2959 | Train Accuracy: 14.59\n",
      "[[851  17 620]\n",
      " [183   1 121]\n",
      " [821  13 561]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.57      0.15      1495\n",
      "           2       0.01      0.00      0.00       305\n",
      "           3       0.08      0.40      0.14      1403\n",
      "\n",
      "   micro avg       0.08      0.44      0.14      3203\n",
      "   macro avg       0.06      0.32      0.10      3203\n",
      "weighted avg       0.08      0.44      0.13      3203\n",
      "\n",
      "Epoch:  12 | Loss: 2.1949 | Train Accuracy: 13.85\n",
      "[[702   1 792]\n",
      " [141   4 160]\n",
      " [672   6 725]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.47      0.14      1495\n",
      "           2       0.04      0.01      0.02       305\n",
      "           3       0.09      0.52      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.45      0.14      3203\n",
      "   macro avg       0.07      0.33      0.10      3203\n",
      "weighted avg       0.08      0.45      0.13      3203\n",
      "\n",
      "Epoch:  13 | Loss: 2.1890 | Train Accuracy: 13.83\n",
      "[[884   4 607]\n",
      " [191   1 113]\n",
      " [852   7 544]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.59      0.15      1495\n",
      "           2       0.02      0.00      0.01       305\n",
      "           3       0.09      0.39      0.14      1403\n",
      "\n",
      "   micro avg       0.09      0.45      0.14      3203\n",
      "   macro avg       0.06      0.33      0.10      3203\n",
      "weighted avg       0.08      0.45      0.13      3203\n",
      "\n",
      "Epoch:  14 | Loss: 2.2607 | Train Accuracy: 12.54\n",
      "[[895   0 600]\n",
      " [198   0 107]\n",
      " [998   4 401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.60      0.14      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.08      0.29      0.12      1403\n",
      "\n",
      "   micro avg       0.08      0.40      0.13      3203\n",
      "   macro avg       0.05      0.29      0.09      3203\n",
      "weighted avg       0.07      0.40      0.12      3203\n",
      "\n",
      "Epoch:  15 | Loss: 2.0881 | Train Accuracy: 14.42\n",
      "[[805   0 690]\n",
      " [147   0 158]\n",
      " [710   6 686]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.54      0.16      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.09      0.49      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.47      0.15      3203\n",
      "   macro avg       0.06      0.34      0.10      3203\n",
      "weighted avg       0.08      0.47      0.14      3203\n",
      "\n",
      "Epoch:  16 | Loss: 2.1148 | Train Accuracy: 14.50\n",
      "[[726   0 769]\n",
      " [149   0 156]\n",
      " [630   0 773]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.49      0.15      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.09      0.55      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.47      0.15      3203\n",
      "   macro avg       0.06      0.35      0.10      3203\n",
      "weighted avg       0.08      0.47      0.14      3203\n",
      "\n",
      "Epoch:  17 | Loss: 1.9813 | Train Accuracy: 13.94\n",
      "[[519   0 976]\n",
      " [105   1 199]\n",
      " [482   1 920]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.35      0.13      1495\n",
      "           2       0.20      0.00      0.01       305\n",
      "           3       0.09      0.66      0.16      1403\n",
      "\n",
      "   micro avg       0.09      0.45      0.14      3203\n",
      "   macro avg       0.12      0.34      0.10      3203\n",
      "weighted avg       0.10      0.45      0.13      3203\n",
      "\n",
      "Epoch:  18 | Loss: 2.0839 | Train Accuracy: 13.65\n",
      "[[779   0 716]\n",
      " [158   0 147]\n",
      " [775   1 627]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.52      0.15      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.08      0.45      0.13      1403\n",
      "\n",
      "   micro avg       0.08      0.44      0.14      3203\n",
      "   macro avg       0.06      0.32      0.10      3203\n",
      "weighted avg       0.08      0.44      0.13      3203\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19 | Loss: 2.0535 | Train Accuracy: 13.91\n",
      "[[687   0 808]\n",
      " [139   0 166]\n",
      " [655   1 747]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.46      0.14      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.09      0.53      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.45      0.14      3203\n",
      "   macro avg       0.06      0.33      0.10      3203\n",
      "weighted avg       0.08      0.45      0.13      3203\n",
      "\n",
      "Epoch:  20 | Loss: 1.9936 | Train Accuracy: 14.42\n",
      "[[776   0 719]\n",
      " [150   0 155]\n",
      " [688   0 715]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.52      0.16      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.09      0.51      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.47      0.15      3203\n",
      "   macro avg       0.06      0.34      0.10      3203\n",
      "weighted avg       0.08      0.47      0.14      3203\n",
      "\n",
      "Epoch:  21 | Loss: 2.0857 | Train Accuracy: 13.39\n",
      "[[597   0 898]\n",
      " [126   0 179]\n",
      " [616   0 787]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.40      0.13      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.08      0.56      0.15      1403\n",
      "\n",
      "   micro avg       0.08      0.43      0.14      3203\n",
      "   macro avg       0.05      0.32      0.09      3203\n",
      "weighted avg       0.07      0.43      0.13      3203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  22 | Loss: 2.0066 | Train Accuracy: 14.84\n",
      "[[846   0 649]\n",
      " [162   0 143]\n",
      " [715   0 688]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.57      0.16      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.09      0.49      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.48      0.15      3203\n",
      "   macro avg       0.06      0.35      0.10      3203\n",
      "weighted avg       0.08      0.48      0.14      3203\n",
      "\n",
      "Epoch:  23 | Loss: 2.0552 | Train Accuracy: 13.78\n",
      "[[575   0 920]\n",
      " [122   0 183]\n",
      " [553   0 850]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.38      0.14      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.08      0.61      0.15      1403\n",
      "\n",
      "   micro avg       0.08      0.44      0.14      3203\n",
      "   macro avg       0.06      0.33      0.10      3203\n",
      "weighted avg       0.08      0.44      0.13      3203\n",
      "\n",
      "Epoch:  24 | Loss: 2.0422 | Train Accuracy: 14.15\n",
      "[[727   0 768]\n",
      " [154   0 151]\n",
      " [667   0 736]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.49      0.15      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.09      0.52      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.46      0.15      3203\n",
      "   macro avg       0.06      0.34      0.10      3203\n",
      "weighted avg       0.08      0.46      0.13      3203\n",
      "\n",
      "Epoch:  25 | Loss: 1.9744 | Train Accuracy: 14.06\n",
      "[[699   0 796]\n",
      " [144   0 161]\n",
      " [649   0 754]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.47      0.14      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.09      0.54      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.45      0.15      3203\n",
      "   macro avg       0.06      0.33      0.10      3203\n",
      "weighted avg       0.08      0.45      0.13      3203\n",
      "\n",
      "Epoch:  26 | Loss: 1.9893 | Train Accuracy: 14.47\n",
      "[[791   0 704]\n",
      " [180   0 125]\n",
      " [698   0 705]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.53      0.15      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.09      0.50      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.47      0.15      3203\n",
      "   macro avg       0.06      0.34      0.10      3203\n",
      "weighted avg       0.08      0.47      0.14      3203\n",
      "\n",
      "Epoch:  27 | Loss: 2.0039 | Train Accuracy: 14.26\n",
      "[[698   0 797]\n",
      " [132   2 171]\n",
      " [628   1 774]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.47      0.15      1495\n",
      "           2       0.12      0.01      0.01       305\n",
      "           3       0.09      0.55      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.46      0.15      3203\n",
      "   macro avg       0.10      0.34      0.10      3203\n",
      "weighted avg       0.09      0.46      0.14      3203\n",
      "\n",
      "Epoch:  28 | Loss: 1.9839 | Train Accuracy: 14.72\n",
      "[[742   2 751]\n",
      " [164   1 140]\n",
      " [621   3 779]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.50      0.15      1495\n",
      "           2       0.06      0.00      0.01       305\n",
      "           3       0.09      0.56      0.16      1403\n",
      "\n",
      "   micro avg       0.09      0.48      0.15      3203\n",
      "   macro avg       0.08      0.35      0.11      3203\n",
      "weighted avg       0.09      0.48      0.14      3203\n",
      "\n",
      "Epoch:  29 | Loss: 1.9780 | Train Accuracy: 13.68\n",
      "[[658   0 837]\n",
      " [127   1 177]\n",
      " [648   0 755]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.44      0.14      1495\n",
      "           2       0.09      0.00      0.01       305\n",
      "           3       0.08      0.54      0.15      1403\n",
      "\n",
      "   micro avg       0.08      0.44      0.14      3203\n",
      "   macro avg       0.09      0.33      0.10      3203\n",
      "weighted avg       0.08      0.44      0.13      3203\n",
      "\n",
      "Epoch:  30 | Loss: 1.9827 | Train Accuracy: 15.24\n",
      "[[1033    1  461]\n",
      " [ 230    1   74]\n",
      " [ 862    0  541]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      0.69      0.17      1495\n",
      "           2       0.11      0.00      0.01       305\n",
      "           3       0.09      0.39      0.14      1403\n",
      "\n",
      "   micro avg       0.09      0.49      0.16      3203\n",
      "   macro avg       0.10      0.36      0.11      3203\n",
      "weighted avg       0.09      0.49      0.14      3203\n",
      "\n",
      "Epoch:  31 | Loss: 2.0391 | Train Accuracy: 14.70\n",
      "[[989   0 506]\n",
      " [192   0 113]\n",
      " [871   1 531]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.66      0.16      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.09      0.38      0.14      1403\n",
      "\n",
      "   micro avg       0.09      0.47      0.15      3203\n",
      "   macro avg       0.06      0.35      0.10      3203\n",
      "weighted avg       0.08      0.47      0.14      3203\n",
      "\n",
      "Epoch:  32 | Loss: 2.0140 | Train Accuracy: 14.83\n",
      "[[1053    0  442]\n",
      " [ 226    0   79]\n",
      " [ 920    3  480]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.70      0.16      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.10      0.34      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.48      0.15      3203\n",
      "   macro avg       0.06      0.35      0.10      3203\n",
      "weighted avg       0.08      0.48      0.14      3203\n",
      "\n",
      "Epoch:  33 | Loss: 1.9911 | Train Accuracy: 13.81\n",
      "[[707   4 784]\n",
      " [155   0 150]\n",
      " [681   1 721]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.47      0.14      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.09      0.51      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.45      0.14      3203\n",
      "   macro avg       0.06      0.33      0.10      3203\n",
      "weighted avg       0.08      0.45      0.13      3203\n",
      "\n",
      "Epoch:  34 | Loss: 1.9567 | Train Accuracy: 14.56\n",
      "[[794   4 697]\n",
      " [166   6 133]\n",
      " [692   6 705]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.53      0.15      1495\n",
      "           2       0.06      0.02      0.03       305\n",
      "           3       0.09      0.50      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.47      0.15      3203\n",
      "   macro avg       0.08      0.35      0.11      3203\n",
      "weighted avg       0.09      0.47      0.14      3203\n",
      "\n",
      "Epoch:  35 | Loss: 1.9951 | Train Accuracy: 14.27\n",
      "[[874   6 615]\n",
      " [161   1 143]\n",
      " [800   3 600]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.58      0.16      1495\n",
      "           2       0.03      0.00      0.01       305\n",
      "           3       0.08      0.43      0.14      1403\n",
      "\n",
      "   micro avg       0.09      0.46      0.15      3203\n",
      "   macro avg       0.07      0.34      0.10      3203\n",
      "weighted avg       0.08      0.46      0.14      3203\n",
      "\n",
      "Epoch:  36 | Loss: 1.9590 | Train Accuracy: 15.62\n",
      "[[880   1 614]\n",
      " [151   1 153]\n",
      " [670   1 732]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      0.59      0.17      1495\n",
      "           2       0.04      0.00      0.01       305\n",
      "           3       0.09      0.52      0.16      1403\n",
      "\n",
      "   micro avg       0.10      0.50      0.16      3203\n",
      "   macro avg       0.08      0.37      0.11      3203\n",
      "weighted avg       0.09      0.50      0.15      3203\n",
      "\n",
      "Epoch:  37 | Loss: 2.0197 | Train Accuracy: 13.59\n",
      "[[703   5 787]\n",
      " [153   1 151]\n",
      " [697   5 701]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.47      0.15      1495\n",
      "           2       0.02      0.00      0.01       305\n",
      "           3       0.08      0.50      0.14      1403\n",
      "\n",
      "   micro avg       0.08      0.44      0.14      3203\n",
      "   macro avg       0.06      0.32      0.10      3203\n",
      "weighted avg       0.08      0.44      0.13      3203\n",
      "\n",
      "Epoch:  38 | Loss: 2.0770 | Train Accuracy: 13.26\n",
      "[[798   1 696]\n",
      " [172   0 133]\n",
      " [826   4 573]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.53      0.14      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.08      0.41      0.13      1403\n",
      "\n",
      "   micro avg       0.08      0.43      0.14      3203\n",
      "   macro avg       0.05      0.31      0.09      3203\n",
      "weighted avg       0.07      0.43      0.13      3203\n",
      "\n",
      "Epoch:  39 | Loss: 2.0371 | Train Accuracy: 13.65\n",
      "[[726   1 768]\n",
      " [151   0 154]\n",
      " [718   0 685]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.49      0.16      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.08      0.49      0.13      1403\n",
      "\n",
      "   micro avg       0.08      0.44      0.14      3203\n",
      "   macro avg       0.06      0.32      0.10      3203\n",
      "weighted avg       0.08      0.44      0.13      3203\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  40 | Loss: 2.0340 | Train Accuracy: 13.26\n",
      "[[614   0 881]\n",
      " [136   1 168]\n",
      " [643   4 756]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.07      0.41      0.13      1495\n",
      "           2       0.05      0.00      0.01       305\n",
      "           3       0.09      0.54      0.15      1403\n",
      "\n",
      "   micro avg       0.08      0.43      0.14      3203\n",
      "   macro avg       0.07      0.32      0.09      3203\n",
      "weighted avg       0.08      0.43      0.13      3203\n",
      "\n",
      "Epoch:  41 | Loss: 2.0468 | Train Accuracy: 13.92\n",
      "[[595  12 888]\n",
      " [135   3 167]\n",
      " [556   6 841]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.40      0.14      1495\n",
      "           2       0.05      0.01      0.02       305\n",
      "           3       0.09      0.60      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.45      0.14      3203\n",
      "   macro avg       0.07      0.34      0.10      3203\n",
      "weighted avg       0.08      0.45      0.13      3203\n",
      "\n",
      "Epoch:  42 | Loss: 2.0291 | Train Accuracy: 14.19\n",
      "[[814   6 675]\n",
      " [173   0 132]\n",
      " [749   1 653]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.54      0.16      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.08      0.47      0.14      1403\n",
      "\n",
      "   micro avg       0.09      0.46      0.15      3203\n",
      "   macro avg       0.06      0.34      0.10      3203\n",
      "weighted avg       0.08      0.46      0.13      3203\n",
      "\n",
      "Epoch:  43 | Loss: 2.0082 | Train Accuracy: 14.39\n",
      "[[832   1 662]\n",
      " [169   2 134]\n",
      " [749   0 654]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.56      0.16      1495\n",
      "           2       0.09      0.01      0.01       305\n",
      "           3       0.09      0.47      0.14      1403\n",
      "\n",
      "   micro avg       0.09      0.46      0.15      3203\n",
      "   macro avg       0.09      0.34      0.10      3203\n",
      "weighted avg       0.09      0.46      0.14      3203\n",
      "\n",
      "Epoch:  44 | Loss: 2.0195 | Train Accuracy: 14.25\n",
      "[[672   0 823]\n",
      " [130   0 175]\n",
      " [602   0 801]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.45      0.15      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.09      0.57      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.46      0.15      3203\n",
      "   macro avg       0.06      0.34      0.10      3203\n",
      "weighted avg       0.08      0.46      0.14      3203\n",
      "\n",
      "Epoch:  45 | Loss: 1.9559 | Train Accuracy: 14.20\n",
      "[[868  12 615]\n",
      " [144   1 160]\n",
      " [803   1 599]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.58      0.15      1495\n",
      "           2       0.02      0.00      0.01       305\n",
      "           3       0.09      0.43      0.14      1403\n",
      "\n",
      "   micro avg       0.09      0.46      0.15      3203\n",
      "   macro avg       0.06      0.34      0.10      3203\n",
      "weighted avg       0.08      0.46      0.14      3203\n",
      "\n",
      "Epoch:  46 | Loss: 2.0075 | Train Accuracy: 13.49\n",
      "[[684   9 802]\n",
      " [151   1 153]\n",
      " [690   3 710]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.46      0.14      1495\n",
      "           2       0.01      0.00      0.00       305\n",
      "           3       0.08      0.51      0.14      1403\n",
      "\n",
      "   micro avg       0.08      0.44      0.14      3203\n",
      "   macro avg       0.06      0.32      0.10      3203\n",
      "weighted avg       0.08      0.44      0.13      3203\n",
      "\n",
      "Epoch:  47 | Loss: 1.9000 | Train Accuracy: 15.53\n",
      "[[792   0 703]\n",
      " [138   0 167]\n",
      " [589   1 813]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      0.53      0.17      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.09      0.58      0.16      1403\n",
      "\n",
      "   micro avg       0.10      0.50      0.16      3203\n",
      "   macro avg       0.06      0.37      0.11      3203\n",
      "weighted avg       0.09      0.50      0.15      3203\n",
      "\n",
      "Epoch:  48 | Loss: 1.9627 | Train Accuracy: 14.93\n",
      "[[885   2 608]\n",
      " [154   1 150]\n",
      " [745   0 658]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.59      0.16      1495\n",
      "           2       0.09      0.00      0.01       305\n",
      "           3       0.09      0.47      0.15      1403\n",
      "\n",
      "   micro avg       0.09      0.48      0.15      3203\n",
      "   macro avg       0.09      0.35      0.11      3203\n",
      "weighted avg       0.09      0.48      0.14      3203\n",
      "\n",
      "Epoch:  49 | Loss: 1.9809 | Train Accuracy: 13.89\n",
      "[[833   1 661]\n",
      " [162   1 142]\n",
      " [801   0 602]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.56      0.15      1495\n",
      "           2       0.04      0.00      0.01       305\n",
      "           3       0.08      0.43      0.14      1403\n",
      "\n",
      "   micro avg       0.09      0.45      0.14      3203\n",
      "   macro avg       0.07      0.33      0.10      3203\n",
      "weighted avg       0.08      0.45      0.13      3203\n",
      "\n",
      "Epoch:  50 | Loss: 1.9638 | Train Accuracy: 14.63\n",
      "[[843   0 652]\n",
      " [178   0 127]\n",
      " [733   1 669]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.56      0.15      1495\n",
      "           2       0.00      0.00      0.00       305\n",
      "           3       0.09      0.48      0.16      1403\n",
      "\n",
      "   micro avg       0.09      0.47      0.15      3203\n",
      "   macro avg       0.06      0.35      0.10      3203\n",
      "weighted avg       0.08      0.47      0.14      3203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPHOCS):  # loop over the dataset multiple times\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    outs = []\n",
    "    golds = []\n",
    "    model.train()\n",
    "    \n",
    "    # TRAINING ROUND\n",
    "    for i, data in enumerate(train_loader):\n",
    "         # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        model.hidden = model.init_hidden() \n",
    "        \n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, N_STEPS, N_INPUTS)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels.long().view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc += get_accuracy(outputs, labels.long().view(-1), BATCH_SIZE)\n",
    "        \n",
    "        out = torch.max(outputs, 1)[1].view(labels.long().view(-1).size()).data\n",
    "        gold = labels.long().view(-1).data\n",
    "        outs.append(out)\n",
    "        golds.append(gold)\n",
    "         \n",
    "    model.eval()\n",
    "    print('Epoch:  %d | Loss: %.4f | Train Accuracy: %.2f' \n",
    "          %(epoch+1, train_running_loss/i, train_acc/(i*N_STEPS)))\n",
    "    \n",
    "    y_pred = torch.cat(outs)\n",
    "    y_gold = torch.cat(golds)\n",
    "\n",
    "    print(confusion_matrix(y_gold, y_pred, labels=[1, 2, 3]))\n",
    "    print(classification_report(y_gold, y_pred, labels=[1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = 0.0\n",
    "outs = []\n",
    "golds = []\n",
    "\n",
    "for i, data in enumerate(valid_loader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(-1, N_STEPS, N_INPUTS)\n",
    "\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    test_acc += get_accuracy(outputs, labels.long().view(-1), BATCH_SIZE)\n",
    "    out = torch.max(outputs, 1)[1].view(labels.long().view(-1).size()).data\n",
    "    gold = labels.long().view(-1).data\n",
    "    outs.append(out)\n",
    "    golds.append(gold)\n",
    "        \n",
    "print('Test Accuracy: %.2f'%(test_acc/(i*N_STEPS)))\n",
    "\n",
    "y_pred = torch.cat(outs)\n",
    "y_gold = torch.cat(golds)\n",
    "\n",
    "print(confusion_matrix(y_gold, y_pred, labels=[1, 2, 3]))\n",
    "print(classification_report(y_gold, y_pred, labels=[1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1 = pd.DataFrame({'speech':[307140,673,894],'silence':[67293,146,147],'filler':[77599,198,292]}, index=[\"speech\", \"silence\", \"filler\"])\n",
    "matrix = sns.heatmap(cm1.T, annot=True, fmt='d', linewidths=.5, cmap='coolwarm')\n",
    "matrix.set(xlabel='predicted label', ylabel='true label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.DataFrame({'speech':[38602,0,0],'silence':[8888,0,0],'filler':[11674,0,0]}, index=[\"speech\", \"silence\", \"filler\"])\n",
    "matrix = sns.heatmap(cm.T, annot=True, fmt='d', linewidths=.5, cmap='coolwarm')\n",
    "matrix.set(xlabel='predicted label', ylabel='true label')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
